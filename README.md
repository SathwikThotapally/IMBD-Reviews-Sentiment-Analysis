# IMDB Reviews Sentiment Analysis

## ğŸ“– Project Overview

This project focuses on **sentiment analysis** of IMDB movie reviews, aiming to classify reviews as **positive** or **negative**. The project demonstrates a complete machine learning workflow for text classification, including **text preprocessing, feature extraction, model training, evaluation, and comparison**.

---

## ğŸ—‚ Dataset

- The dataset consists of **IMDB movie reviews** labeled as positive or negative.
- Each review is a piece of raw text.
- The target variable is `sentiment` (positive/negative).

---

## âœ¨ Text Preprocessing

Text data was preprocessed using **NLTK** and Python libraries. Key steps include:

- **Tokenization** â€“ Splitting text into individual words.  
- **Lowercasing** â€“ Converting all text to lowercase.  
- **Stopwords Removal** â€“ Removing common words that do not contribute to sentiment.  
- **Lemmatization** â€“ Reducing words to their base form (e.g., â€œrunningâ€ â†’ â€œrunâ€).  

These steps ensure that the model focuses on meaningful features and reduces noise in the data.

---

## ğŸ›  Feature Extraction

- **TF-IDF Vectorization** was used to convert text into numerical features.  
- TF-IDF captures the importance of words in a document relative to the entire corpus.  
- Parameters like **n-grams** and **maximum features** can be adjusted to improve performance.

---

## ğŸ¤– Models Used

Three machine learning models were trained and evaluated:

1. **Logistic Regression** â€“ A linear model suitable for high-dimensional, sparse text data.  
2. **Multinomial Naive Bayes** â€“ A probabilistic model commonly used for text classification.  
3. **Random Forest Classifier** â€“ An ensemble method capable of handling complex patterns in the data.

---

## ğŸ“Š Evaluation Metrics

Models were evaluated using:

- **Accuracy** â€“ Overall correctness of predictions.  
- **Precision** â€“ Correctness of positive predictions.  
- **Recall** â€“ Ability to identify all positive samples.  
- **F1-score** â€“ Balance between precision and recall.  

**Result Summary:**  
- Logistic Regression achieved the **highest accuracy and F1-score**, outperforming the other models.  
- Multinomial Naive Bayes performed well but slightly lower than Logistic Regression.  
- Random Forest, while capable, showed lower performance due to high-dimensional sparse features.

---

## ğŸ Conclusion

- Logistic Regression is the **best-performing model** for this problem, highlighting the effectiveness of linear models for sparse text data.  
- Naive Bayes remains competitive for text classification tasks.  
- Random Forest works but may require additional feature engineering or dimensionality reduction.  

**Future Improvements:**  
- Hyperparameter tuning for all models.  
- Experimenting with **n-grams** or **word embeddings** (e.g., Word2Vec, GloVe).  
- Exploring **deep learning models** like LSTM or BERT for better semantic understanding.  

---

ğŸ‘¤ Author: Sathwik Thotapally
ğŸ“§ Email: sathwikthotapally@gmail.com

