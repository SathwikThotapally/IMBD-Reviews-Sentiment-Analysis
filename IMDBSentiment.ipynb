{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5edea7a-313c-4832-afbe-84414ee2d523",
   "metadata": {},
   "source": [
    "# **Project Name**\n",
    "IMDB Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb17c42-132f-4809-953e-26a8c1cccf29",
   "metadata": {},
   "source": [
    "##### **Project Type** - Classification (Supervised Learning)\n",
    "##### **Contribution** - Individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1162ba-5fc2-4484-b1c2-c3199c617677",
   "metadata": {},
   "source": [
    "# **Project Summary**\n",
    "In this project, we build a Machine Learning model to classify IMDB movie reviews into **positive** and **negative** sentiments. The dataset contains two columns: `review` (text data) and `sentiment` (label).\n",
    "\n",
    "The workflow includes:\n",
    "- Preprocessing the text reviews\n",
    "- Converting text into numerical features using vectorization\n",
    "- Training classification models (Logistic Regression, Naive Bayes)\n",
    "- Evaluating performance using accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660d1a9-fa17-44c8-ad4c-1d6bcd057e76",
   "metadata": {},
   "source": [
    "In this project, we conducted a sentiment analysis of IMDB movie reviews, aiming to classify reviews as positive or negative. The workflow started with text preprocessing, where raw textual data was cleaned and prepared for modeling. Key preprocessing steps included tokenization, removal of stopwords, and lemmatization using the NLTK library. These steps were crucial to standardize the text and reduce noise, ensuring that the models could focus on meaningful features.\n",
    "\n",
    "After preprocessing, the text data was converted into numerical features using TF-IDF vectorization, capturing both the importance and frequency of words in the corpus. This representation was then used to train and evaluate three different machine learning models: Logistic Regression, Multinomial Naive Bayes, and Random Forest Classifier.\n",
    "\n",
    "The models were assessed using several performance metrics, including accuracy, precision, recall, and F1-score, to obtain a comprehensive understanding of their predictive power. The comparison revealed that while all three models performed reasonably well, Logistic Regression outperformed the others in this particular problem, achieving the highest overall metrics. Multinomial Naive Bayes performed competitively, as expected for text classification tasks, whereas Random Forest, although capable, showed slightly lower performance, likely due to the high dimensionality and sparsity of TF-IDF features.\n",
    "\n",
    "Overall, the project demonstrates the importance of text preprocessing, feature extraction, and model selection in building an effective sentiment analysis pipeline. The results highlight that for sparse, high-dimensional text data like IMDB reviews, linear models such as Logistic Regression often provide strong performance with simpler implementation compared to more complex ensemble methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd00d869-d455-4f2c-9905-aaf8306a3b28",
   "metadata": {},
   "source": [
    "# **GitHub Link -**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a99216-c298-4c64-89f6-82366e1f63c6",
   "metadata": {},
   "source": [
    "https://github.com/SathwikThotapally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac084708-6617-4056-8817-0a9a251a80b0",
   "metadata": {},
   "source": [
    "# **Problem Statement**\n",
    "Movie reviews often express clear sentiment about films. Automatically classifying these reviews as positive or negative helps companies understand audience feedback at scale. The objective is to design a machine learning model that predicts the sentiment of a review accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0b2c4-a35c-4a78-81a6-c517c6a59d2d",
   "metadata": {},
   "source": [
    "# ***Let's Begin !***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca052e2-f924-4024-a2a8-700d75373492",
   "metadata": {},
   "source": [
    "## ***1. Know Your Data***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1282aba8-7c67-42b1-8820-b06d7a91e82f",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e90f6655-e751-47cc-8f48-049108a30c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b13f6a17-e858-47cf-ba35-df7684985927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sathwik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sathwik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d318-fa48-475a-822f-5239a3ff5b78",
   "metadata": {},
   "source": [
    "### Dataset Loading and Dataset First View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d77d0e-0f17-450a-9aeb-8eeee2b20184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75360ae7-42a5-4db8-aefd-6031e0e5bd3c",
   "metadata": {},
   "source": [
    "### Dataset Rows & Columns count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89c41b7-5b29-415d-9296-9a3b3676026e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1acf2-c43b-4d05-a3db-51ded43b99f7",
   "metadata": {},
   "source": [
    "### Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043e16ab-d260-4510-9127-cde876a0fd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336814f-2271-4534-9ce8-51c2b4b06ee6",
   "metadata": {},
   "source": [
    "#### Missing Values/Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b901c4b-35d8-4985-abda-680320029948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4de719-83d6-4b33-99e9-42743dfad2e5",
   "metadata": {},
   "source": [
    "### What did you know about your dataset?\n",
    "- Dataset: IMDB Movie Reviews\n",
    "- Columns:\n",
    "  - `review`: textual content of movie review\n",
    "  - `sentiment`: target label (positive / negative)\n",
    "- There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf6125-ae94-4c76-9492-06665455e936",
   "metadata": {},
   "source": [
    "## ***2. Understanding Your Variables***\n",
    "- **review:** Feature (unstructured text â†’ needs preprocessing and vectorization).\n",
    "- **sentiment:** Target variable (categorical: positive / negative).\n",
    "\n",
    "*(No need for correlation analysis here since features are text, not numerical.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9738ff7-2378-48e6-a903-a8ffa22e6d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    25000\n",
      "negative    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Counting positive vs neagtive sentiments\n",
    "review_counts = df['sentiment'].value_counts()\n",
    "print(review_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fbf7f-3fd9-4dc2-bcd2-3a77c4c75042",
   "metadata": {},
   "source": [
    "#### So, We can conclude from the above that the labels in the sentiment column are equally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a669e-8398-44c5-aaff-fedd0328463d",
   "metadata": {},
   "source": [
    "## ***3. Data Preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129870c6-f818-4bee-89af-c2f3d9399007",
   "metadata": {},
   "source": [
    "#### ***This step icludes text preprocessing techniques like:***\n",
    "- Convert text to lowercase\n",
    "- Remove HTML tags\n",
    "- Remove punctuation, special characters, and numbers\n",
    "- Remove extra spaces\n",
    "- Stopwords removal\n",
    "- Tokenization\n",
    "- Lemmatization\n",
    "\n",
    "All these steps are wrapped into a single function: preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dab6971-a301-4833-bd11-3e6650522dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>','',text)\n",
    "    text = re.sub(r'[^a-zA-Z]',' ',text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c24689-6c84-4364-9e98-64ca345d7c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                        clean_review  \n",
       "0  one reviewer mentioned watching oz episode hoo...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  petter mattei love time money visually stunnin...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review'] = df['review'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f2003-a146-4d9d-be5b-a26c4b94ef03",
   "metadata": {},
   "source": [
    "#### In the above code we applied the preprocess_text function to our 'review' column and stored the result into a new column - 'clean_review'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4ea37-ce05-480e-be4e-f29840695976",
   "metadata": {},
   "source": [
    "### ***3b. Data Splitting***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef7a6304-0431-4a91-9d65-95d8910368c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0180acec-202e-42e5-b9fb-5c683027582f",
   "metadata": {},
   "source": [
    "### ***3c. Vectorization*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "351959b0-2c05-4c3e-8609-ef0184572ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "\n",
    "X_test_vec = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ffb2e-1d14-48e4-956b-d7584eb31ba3",
   "metadata": {},
   "source": [
    "## ***4. Model Implementation***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d841d0b-8cb6-4c2b-8dfa-9f092d56f7db",
   "metadata": {},
   "source": [
    "### ML Model - 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c4fdaef-db71-4e60-83c8-b4735b23e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8912\n",
      "Precision: 0.8835294117647059\n",
      "Recall   : 0.9012\n",
      "F1-score : 0.8922772277227723\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the algorithm\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on the model\n",
    "y_pred_clf = clf.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_clf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_clf, pos_label=\"positive\"))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_clf, pos_label=\"positive\"))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred_clf, pos_label=\"positive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92701da9-3743-4ce0-98b1-fedcad9d8076",
   "metadata": {},
   "source": [
    "#### Make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a0e9e4-a8af-475a-ad20-b78f74f9200a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  positive\n"
     ]
    }
   ],
   "source": [
    "new_rev = \"I love this movie, it was amazing!\"\n",
    "\n",
    "clean_text = preprocess_text(new_rev)\n",
    "\n",
    "new_vec = tfidf.transform([clean_text])\n",
    "\n",
    "prediction1 = clf.predict(new_vec)[0]\n",
    "\n",
    "print(\"Predicted Sentiment: \",prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2160cc5-7571-4ad7-9f15-748c564cf6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "new_rev1 = \"I hate this movie, it was boring!\"\n",
    "\n",
    "clean_text1 = preprocess_text(new_rev1)\n",
    "\n",
    "new_vec1 = tfidf.transform([clean_text1])\n",
    "\n",
    "prediction2 = clf.predict(new_vec1)[0]\n",
    "\n",
    "print(\"Predicted Sentiment: \",prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aea88e-f082-4f6d-b8e2-53d3bdcaca3c",
   "metadata": {},
   "source": [
    "### ML Model - 2 - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73d33795-b75d-4216-9f26-68ab09688f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8611\n",
      "Precision: 0.8494290690923166\n",
      "Recall   : 0.8778\n",
      "F1-score : 0.8633815284744762\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "\n",
    "# Fit the algorithm\n",
    "mnb.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predict on the model\n",
    "y_pred_mnb = mnb.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_mnb))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_mnb, pos_label=\"positive\"))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_mnb, pos_label=\"positive\"))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred_mnb, pos_label=\"positive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6f126-f4c4-44d4-b73c-1d4c7b6083a9",
   "metadata": {},
   "source": [
    "#### Make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb0d0376-a3d5-47c9-8db9-389749b21ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "new_rev1 = \"I absolutely hate this movie, it was not at all good!\"\n",
    "\n",
    "clean_text1 = preprocess_text(new_rev1)\n",
    "\n",
    "new_vec1 = tfidf.transform([clean_text1])\n",
    "\n",
    "prediction3 = mnb.predict(new_vec1)[0]\n",
    "\n",
    "print(\"Predicted Sentiment: \",prediction3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3d642cb-e09d-46b7-888a-5dd1e17f9a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  positive\n"
     ]
    }
   ],
   "source": [
    "new_rev2 = \"I loved this movie, it was nice to watch!\"\n",
    "\n",
    "clean_text2 = preprocess_text(new_rev2)\n",
    "\n",
    "new_vec2 = tfidf.transform([clean_text2])\n",
    "\n",
    "prediction4 = clf.predict(new_vec2)[0]\n",
    "\n",
    "print(\"Predicted Sentiment: \",prediction4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf9cb812-fdba-475e-a291-2398fad4e42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8405\n",
      "Precision: 0.8153361733654381\n",
      "Recall   : 0.8804\n",
      "F1-score : 0.8466198672949322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42)\n",
    "\n",
    "rf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred_rf, pos_label=\"positive\"))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred_rf, pos_label=\"positive\"))\n",
    "print(\"F1-score :\", f1_score(y_test, y_pred_rf, pos_label=\"positive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a62a15cb-d713-41c8-a7b8-ab01c585009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  negative\n"
     ]
    }
   ],
   "source": [
    "new_rev3 = \"I absolutely hate this movie, it was not at all good!\"\n",
    "\n",
    "clean_text3 = preprocess_text(new_rev3)\n",
    "\n",
    "new_vec3 = tfidf.transform([clean_text3])\n",
    "\n",
    "prediction5 = mnb.predict(new_vec3)[0]\n",
    "\n",
    "print(\"Predicted Sentiment: \",prediction5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa716079-d7d1-43a5-b804-16d4ae118047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment:  positive\n"
     ]
    }
   ],
   "source": [
    "new_rev4 = \"It was honestly a great movie, it was very nice to watch!\"\n",
    "\n",
    "clean_text4 = preprocess_text(new_rev4)\n",
    "\n",
    "new_vec4 = tfidf.transform([clean_text4])\n",
    "\n",
    "prediction6 = mnb.predict(new_vec4)[0]\n",
    "\n",
    "print(\"Predicted Sentiment: \",prediction6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9c0ef-a67b-467d-9647-a05081962be2",
   "metadata": {},
   "source": [
    "# **Conclusion**\n",
    "The IMDB Sentiment Analysis project successfully demonstrated the end-to-end process of building a text classification system. Through preprocessing, feature engineering, and model evaluation, we were able to classify movie reviews with reasonable accuracy. Logistic Regression emerged as the most effective model for this dataset, highlighting the suitability of linear models for high-dimensional, sparse text data.\n",
    "\n",
    "The study also shows that while ensemble methods like Random Forest can be applied to text classification, their performance may not always surpass simpler, well-tuned models such as Logistic Regression or Naive Bayes. Future improvements could include hyperparameter tuning, experimenting with n-grams, or using word embeddings to capture semantic meaning, which could further enhance predictive performance. Overall, this project provides a solid foundation for sentiment analysis tasks and illustrates best practices in text preprocessing, feature extraction, and model evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
